[
  {
    "artist": "Test Student",
    "instagram": "https://www.instagram.com/teststudent/",
    "website": "https://website.com",
    "vimeo": "https://vimeo.com/test-student",
    "title": "Title",
    "year": "Year",
    "medium": "Medium",
    "materials": "Materials",
    "statement": "Statement",
    "description": "Description",
    "credit": "Credit",
    "media": ["1.jpg", "2.jpg", "3.jpg", "4.mp4", "5.jpg", "6.jpg", "7.jpg", "8.jpg"],
    "include": false
  },
  {
    "artist": "Alyssa Cheng",
    "instagram": "",
    "vimeo": "",
    "website": "",
    "title": "Reconstruction",
    "year": "2021",
    "medium": "Video",
    "materials": "StyleGAN2-ADA Latent Space Interpolation",
    "statement": "Alyssa Cheng is a multidisciplinary artist who works on fashion and materials. In the project, <i>Reconstruction</i>, she explores how fashion could be combined with technologies to develop a new perspective. By using AI technology to flatten the 3D garments, the garments are transformed into changing pixels and into the language of images. This process turns the produced garments back into the designer's computer and becomes a source of inspiration for designing.",
    "description": "There are 2354 images in the dataset. All images in the database are from all Alexander McQueen runway shows from 1995 to 2010. This project uses StyleGAN2-ADA as Machine Learning model, and it is trained in Google Colab.",
    "credit": "Vogue Runway for images involved in the creation of the dataset, Derrick Schultz for the creation of the StyleGAN2-ADA-PyTorch repo/notebook",
    "media": ["alyssa-cheng1.mp4"],
    "include": true
  },
  {
    "artist": "Benjamin Glass",
    "instagram": "https://www.instagram.com/ben_g.lass/",
    "website": "",
    "vimeo": "https://vimeo.com/twdfilms/",
    "title": "Reconstruction",
    "year": "2021",
    "medium": "Single Channel Video, Images",
    "materials": "StyleGAN2-ADA Latent Space Interpolation video and images.",
    "statement": "The <i>Your_Son 2021</i> project explores the latency of age as it appears in synthetic imagery. In this work the artists trained an image generation model from a selection of around 3000 images taken throughout their entire life. After training, the model was capable of generating 500 of its own synthetic images which where organized and cataloged by perceived age by the parents of the artist, creating a second round of image discrimination fascilitated by human processes. The resulting work is a 9 and a half minute video that interpolates between 20 images, an image for each year of the artist’s life.",
    "description": "The dataset is composed of exactly 2,782 images. The majority of images were harvested digitally from social media accounts in which I was featured as well as those existing on hard drives and cameras. Many images were scanned into digital files from family photobooks and physical images in the homes of family. StyleGAN2-ADA, Align_Faces, RunwayML Green Screen, combined training time of 30 hours, through Google Colab, using primarily a Tesla P100 Nvidia GPU, Latent Space interpolation in the “w” space.",
    "credit": "Derrick Shultz for the StyleGAN2-ADA-PyTorch notebook, Doug Rosman for the CVML/Dataset tools repo, Nicole & Kevin Glass.",
    "media": ["Your_Son2021_2.mp4", "ContactSheet-001.jpg", "ContactSheet-002.jpg", "ContactSheet-003.jpg", "ContactSheet-004.jpg", "ContactSheet-005.jpg", "ContactSheet-006.jpg", "ContactSheet-007.jpg", "ContactSheet-008.jpg", "ContactSheet-009.jpg", "ContactSheet-010.jpg", "ContactSheet-011.jpg", "ContactSheet-012.jpg", "ContactSheet-013.jpg", "ContactSheet-014.jpg", "ContactSheet-015.jpg", "ContactSheet-016.jpg", "ContactSheet-017.jpg", "ContactSheet-018.jpg", "ContactSheet-019.jpg", "ContactSheet-020.jpg"],
    "include": true
  },
  {
    "artist": "Boomer Scripps",
    "instagram": "https://www.instagram.com/boomerscrippsdoesnotexist/",
    "website": "https://boomerscrippsdoesnotexist.com/",
    "vimeo": "",
    "title": "Dreaming of Forgotten Memories",
    "year": "2021",
    "medium": "Video",
    "materials": "StyleGAN2-ADA Latent Space Interpolation",
    "statement": "This piece uses StyleGAN2-ADA trained on images of my hometown, Boulder, Colorado. Boulder and the surrounding area has gone through a lot of rapid and traumatic changes over the past year, to the point that it feels divorced form my own memories of it. With this piece I am trying to work through my own fractured memories of my hometown given that I can’t see anymore.",
    "description": "My data set has 43 images. I made all my images over the past ~year and a half with a medium format film camera (Hasselblad 500C/). Trained using NVLab's StyleGAN2-ADA. Latent space interpolation videos generated using circular interpolation from Derrick Schultz' Colab Notebook.",
    "credit": "Derrick Shultz for the StyleGAN2-ADA-PyTorch notebook",
    "media": ["vid_1_1.mp4","vid_2_1.mp4","vid_3_1.mp4","vid_4_1.mp4","vid_5_1.mp4","vid_6_1.mp4","vid_7_1.mp4","vid_8_1.mp4","vid_9_1.mp4","vid_10_1.mp4","vid_11_1.mp4","vid_12_1.mp4","vid_13_1.mp4","vid_14_1.mp4","vid_15_1.mp4"],
    "include": true
  },
  {
    "artist": "Daniella Thach",
    "instagram": "https://www.instagram.com/uglyneon/",
    "website": "https://daniellathach.wixsite.com/artist/",
    "vimeo": "",
    "title": "Dreaming of Forgotten Memories",
    "year": "2021",
    "medium": "Digital video projection, appropriated painting",
    "materials": "StyleGAN2-ADA Latent Space Interpolation",
    "statement": "Daniella Thach is a multidisciplinary artist utilizing old and new lighting technologies. Their diasporic work reconciles with the inevitable loss of heritage through the inability to speak her mother tongue. By putting archaic and contemporary mediums in conversation, she bridges the gap in her cultural identity where linguistic language could not.<br><br>An image that has grown up with me are depictions of apsara dancers in the paintings and wood carvings hung on the walls of my childhood home. My dataset is composed of stills taken from an excerpt of Apsara (1966) of Princess Norrodom Buppha Devi's dance. The film is a Cambodian romantic drama edited, written, and directed by the former King and Cambodia's Head of State, Norodom Sihanouk to counter the negative portrayal of the country he saw in the 1965 British-American film Lord Jim. I have not seen the entire movie but I was entranced by her dance. I rarely see apsara dances being performed but when I do, it is a glamorous spectacle, tinted in nostalgia from a time and place that I was not a part of. My reverence to this dance is distanced, and so came the experimentation to distort this video through algorithmic processes to visually communicate my warped sense of identity as a Cambodian American.",
    "description": "The dataset has about 1600 stills from Buppha Devi's dance. The clip from the film was downloaded from YouTube and the .mp4 file was broken down into frames through ffmpeg. I lost track of how long I trained my model through Google Colab after 16 hours. I used StyleGan2-ADA and this interpolation is a noise loop with a 8.0 diameter using seed 68.",
    "credit": "I want to thank Derrick Schultz for developing the StyleGAN2-ADA Colab Notebook, making machine learning very accessible to newbies like me. I extend this thanks to Doug Rosman and Blake Fall-Conroy for teaching me how to use Derrick's repo and creating a super easy to navigate Colab Notebook. I want to also acknowledge the Devata research organization for preserving the film I pulled my dataset from, and of course for their ongoing preservation of Southeast Asian women in art.",
    "media": ["as-an-apsara-ai.mp4"],
    "include": true
  },
  {
    "artist": "Henry Boeschenstein",
    "instagram": "",
    "website": "",
    "vimeo": "",
    "title": "Data Center (Scanimations)",
    "year": "2021",
    "medium": "Video",
    "materials": "Pix2PixHD",
    "statement": "",
    "description": "",
    "credit": "",
    "warning": "video contains intense flickering/strobing throughout.",
    "media": ["henry1.mp4"],
    "include": true
  },
  {
    "artist": "Jieun Hong",
    "instagram": "",
    "website": "",
    "vimeo": "",
    "title": "Pavilion",
    "year": "2021",
    "medium": "Video, Website",
    "materials": "StyleGAN2-ADA Latent Space Interpolation, 3D objects",
    "statement": "",
    "description": "",
    "credit": "",
    "preContent": "<a href='https://jhong36.github.io/computer_vision/threejs/3d_model/pavilion/' target='_blank'>View interactive 3D model</a>",
    "warning": "",
    "media": ["jieun-hong1.mp4", "Pavilion01.jpg", "Pavilion02.png"],
    "postContent": "",
    "include": true
  },
  {
    "artist": "Keming Li",
    "instagram": "https://www.instagram.com/keming_li_29 /",
    "website": "https://www.kemingli.com/wave-ballet",
    "vimeo": "",
    "title": "Wave Ballet",
    "year": "2021",
    "medium": "Video",
    "materials": "StyleGAN2-ADA Latent Space Interpolation",
    "statement": "The work, <i>Wave Ballet</i> is a visual experimentation of dancing human forms and the ever changing sea waves. The artist created several Latent space interpolation videos with StyleGAN2-ADA-PyTorch repo/notebook, by training the data set of wave and ballet together. The figures morph into different dancing gestures, indicating a ghostly presence of time and existence, creating a connection between the dynamic waves and human body.",
    "description": "Around 1200 images in wave data set and 1200 images in ballet data set. The images come from cc0 videos online, extracted with ffmpeg. StyleGAN2-ADA model trained using google colab. Latent space interpolation Technique: Circular Loop (from Derrick Schultz' StyleGAN2-ADA Colab Notebook.",
    "credit": "StyleGAN2-ADA-Pytorch, NVIDIA Corporation, Tero Karras, Janne Hellsten, Public Domain Videos of wave and ballerina from Pixabay (Free for commercial use, No attribution required), Derrick Schultz who created the StyleGAN2-ADA-PyTorch Colab notebook, Music Credit to Lloyd Rodgers - On Questions of Responsibility (Act II) (Public Domain music)",
    "preContent": "",
    "warning": "",
    "media": ["keming-li1.mp4"],
    "postContent": "",
    "include": true
  },
  {
    "artist": "Li Zhu",
    "instagram": "",
    "website": "https://zhuli.info/humandustpix2pix",
    "vimeo": "",
    "title": "HumanDust_Pix2Pix",
    "year": "2021",
    "medium": "Video",
    "materials": "Pix2PixHD",
    "statement": "",
    "description": "The model was trained in Google Colab, with a dataset of about 2000 images extracted from a video created using Unity3D.",
    "credit": "Doug Rosman's pix2pixHD Colab Notebook",
    "preContent": "",
    "warning": "",
    "media": ["li-zhu1.mp4", "li-zhu2.mp4", "li-zhu3.mp4"],
    "postContent": "",
    "include": true
  },
  {
    "artist": "Max Weiss",
    "instagram": "#",
    "website": "#",
    "media": ["1.jpg", "2.jpg", "3.jpg", "4.mp4", "5.jpg", "6.jpg", "7.jpg", "8.jpg"],
    "statement": "statement",
    "description": "description",
    "credit": "credit",
    "include": true
  },
  {
    "artist": "Sean Cheng",
    "instagram": "#",
    "website": "#",
    "media": ["1.jpg", "2.jpg", "3.jpg", "4.mp4", "5.jpg", "6.jpg", "7.jpg", "8.jpg"],
    "statement": "statement",
    "description": "description",
    "credit": "credit",
    "include": true
  },
  {
    "artist": "Victoria Yang",
    "instagram": "#",
    "website": "#",
    "media": ["1.jpg", "2.jpg", "3.jpg", "4.mp4", "5.jpg", "6.jpg", "7.jpg", "8.jpg"],
    "statement": "statement",
    "description": "description",
    "credit": "credit",
    "include": true
  }
]